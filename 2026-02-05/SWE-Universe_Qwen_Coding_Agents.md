# SWE-Universe: Scaling Training Environments for Coding Agents

**Author:** Binyuan Hui (@huybery)  
**Affiliation:** Alibaba Qwen Team  
**Source:** https://x.com/huybery/status/2019072773818360270  
**Paper:** https://huggingface.co/papers/2602.02361  
**Date:** Feb 5, 2026  
**Views:** 21.8K

---

## æ ¸å¿ƒé—®é¢˜

> How to scale training environments for coding agents? 
> 
> **Let the agent build their own!** ğŸ™Œ

---

## SWE-Universe ä»‹ç»

**SWE-Universe** ğŸª æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿï¼š

- å°† **GitHub PRs** è½¬åŒ–ä¸ºçœŸå®ä¸–ç•Œçš„ SWE ç¯å¢ƒ
- æ”¯æŒ **å¤šè¯­è¨€** (Multilingual)
- ç”Ÿæˆ **å¯éªŒè¯** (Verifiable) çš„ç¯å¢ƒ
- Agent åƒäººç±»ä¸“å®¶ä¸€æ ·é…ç½®æ¯ä¸ªç¯å¢ƒ
- é¢å¤–çš„å¯é æ€§ä¿éšœæªæ–½

---

## æ•°æ®é›†è§„æ¨¡å¯¹æ¯”

| Dataset | Instances | Type |
|---------|-----------|------|
| SWE-Bench | 2,294 | Python-only |
| SWE-Gym | 2,438 | Python-only |
| Multi-SWE-RL | 4,723 | Multilingual |
| SWE-rebench | 21,000 | - |
| DeepSeek-V3.2 | 24,667 | - |
| CWM | 35,000 | - |
| MiMo-V2-Flash | 90,000 | - |
| **SWE-Universe (Ours)** | **807,693** | **Multilingual** |

> ğŸ“Š SWE-Universe æ¯”æœ€å¤§çš„ç«äº‰å¯¹æ‰‹å¤§ **9å€**ï¼

---

## éªŒè¯ä¸åº”ç”¨

å·²åœ¨ä»¥ä¸‹åœºæ™¯éªŒè¯ï¼š

1. **Mid-training** for Qwen3-Coder-Next
2. **Reinforcement Learning (RL)** for Qwen3-Coder-Next

æœªæ¥æ–¹å‘ï¼š
- è¿›ä¸€æ­¥æ¨è¿› environment synthesis
- å®ç° **agent self-improvement** çš„è·¯å¾„

---

## ç›¸å…³å‘å¸ƒï¼šQwen3-Coder-Next

**@Alibaba_Qwen Â· Feb 4:**

> ğŸš€ Introducing **Qwen3-Coder-Next**, an open-weight LM built for coding agents & local development.
>
> What's new:
> - ğŸ¤– Scaling agentic training: 800K verifiable tasks + executable envs
> - ğŸ“ˆ Efficiencyâ€“Performance Tradeoff: achieves strong results on SWE-Bench Pro with 80B total params

---

## ç¤¾åŒºåå“

> "A dataset of these tasks, that is open-source and easy to augment through agents just running on compute machines could lead to AGI at least in coding. And it's gonna be in like 1 month from now, distributed across computers." - @Aero96193997

> "What if agents could learn from each other's environments instead of building their own from scratch? This approach could speed up the training process." - @bygregorr

> "This is amazing, any thoughts on whether this could work in domains outside of code (still verifiable, but ood for current models)" - @TheodoreGalanos

---

## Key Takeaways

1. **è§„æ¨¡æ˜¯å…³é”®**: 807K å¯éªŒè¯ç¯å¢ƒï¼Œè¿œè¶…ç°æœ‰æ•°æ®é›†
2. **å¤šè¯­è¨€æ”¯æŒ**: ä¸ä»…é™äº Python
3. **Agent è‡ªä¸»é…ç½®**: è®© agent è‡ªå·±æ„å»ºè®­ç»ƒç¯å¢ƒ
4. **Self-improvement è·¯å¾„**: æŒ‡å‘ coding agent çš„è‡ªæˆ‘æå‡
5. **å¼€æ”¾æƒé‡**: Qwen3-Coder-Next æ˜¯å¼€æ”¾æ¨¡å‹

---

## Links

- Paper: https://huggingface.co/papers/2602.02361
- Tweet: https://x.com/huybery/status/2019072773818360270
- Qwen: https://twitter.com/Alibaba_Qwen
- Author: https://twitter.com/huybery

---

## Hashtags

#SWEUniverse #Qwen #CodingAgents #SWEBench #OpenSource #Alibaba #AGI

---

*æ•´ç†äº 2026-02-05*
